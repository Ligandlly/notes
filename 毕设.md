# 毕设

## 1

主要工作：

1.   生成了文言文分词的词库
2.   设计并实现了文言文分词词典
3.   综合起来开发文言文分词工具

## 3

文言文分词词库是用的**统计现有的分词工具的结果**的方法，把结果存在数据库中：词语本身、出现的句子的序号、在句子中的位置、出现的文章、所使用的分词工具的名字、词性

## 4

GROUP BY

## 5

如果把**所有的结果都录入**到词库里面**效果不好**，所以要删掉一些频率太低的词，

这里测试了**阈值和分词的F值之间的关系**，得到了旁边这张图，最后选的是**9**作为阈值。

## 7

首先是把句子标好id之后存在磁盘上的数据库里面，因为这个如果存在内存里面会浪费很大的内存空间。

文言文分词索引是一个嵌套的词典，为了区分把里面红色的这个词典叫**内层词典**，外面蓝色的词典叫**外层词典**。

外层词典的**key是词语**，**value是内层词典**。

内层词典的key是句子的id，value是词语在句子中出现的位置。

这样做主要是为了查询多个词的时候把这些词出现的句子**求交集**，对哈希表求是只能在key上求交集。

## 8

**实现词典**最高效的方式就是哈希表，因为哈希表在查询时的**平均时间复杂度**是常数。

这里介绍一下我在毕设里面用到的两种哈希表。

第一种是杜鹃哈希，我先简单地介绍一下它的结构。

杜鹃哈希是有两个哈希表组成的，两个哈希表有不一样的哈希函数。

>   插入、查询、删除

插入时先看第一个表是否有空位……

## 9

在杜鹃哈希里面定义了两个常量，一个是

## 10

它的**删除操作是可逆的**，不会对哈希表带来副作用，所以特别的高效，从旁边这张图就可以看出来，这样它在求交集的时候会比较快。

还有一个优点就是它的查询操作的最差的时间复杂度仍然是常数，在毕设里面就是在最差的情况下也只用访问两次内存。

但是杜鹃哈希也有一些问题，第一是它占用的**内存比较大**，第二是它平均的**查询效率**不如线性探查法的哈希表。

## 11

Swisstable是一个基于**线性探查法**的哈希表，它大致的结构是这样的。

在前面的一小部分是一个**元数据**，后面的是元素。

每个元素对应一个**元数据**，有8位，第一位是标志位为0的时候表示有效，剩下7位是对应哈希值的后7位。

在查询数据时，Swisstable会使用一条**单指令多数据指令**，这条指令可以在**一个时钟周期内完成16字节的比较**，这样就可以缩短查找所需的时钟周期。

## 12

最后实际的实现方法是外层词典用的Swisstable，内层词典用的杜鹃哈希。因为内层的词典会求交集，外层不会。

## 14

首先来介绍一下整个文言文检索工具的结构，有一个**用户界面**，实际上就是一个**网页**，这是用**React**实现的，

在网页之下有一个**服务器程序**，是用的Python的一个后端框架**Flask**，

最底层是用**Rust**实现的**文言文分词索引**，**数据库**是使用的**Sqlite3**。

## 15

用户界面有**两个界面**，一个**普通用户的查询界面**和**管理员界面**。

普通用户界面只有查询功能，在输入框中输入要查询的词语，用英语分号隔开。

然后服务器就会找到包含了所有待搜索词的句子，也包括句子所在的文章名然后在网页上显示出来，同时还会显示**查询总共用时和其中哈希表用的时间**。

## 16

管理员界面在管理员输入正确的密码登录后可以上传文件，文件上传后服务器会分词并且添加到索引中，这样在查询的时候就可以找到了,文件处理结束后也会显示**文件处理的时间**和**哈希表的时间**，

管理员界面还可以修改管理员密码

## 18



